{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9295168,"sourceType":"datasetVersion","datasetId":5627634},{"sourceId":9295603,"sourceType":"datasetVersion","datasetId":5627926},{"sourceId":9295861,"sourceType":"datasetVersion","datasetId":5628105},{"sourceId":9295916,"sourceType":"datasetVersion","datasetId":5628149},{"sourceId":9479347,"sourceType":"datasetVersion","datasetId":5765776},{"sourceId":9479351,"sourceType":"datasetVersion","datasetId":5765779}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Hello World\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = (224, 224, 3)\nnum_classes = 2 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights_path = '/kaggle/input/weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\nbase_model = MobileNetV2(weights = weights_path, include_top=False, input_shape=input_shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load pre-trained MobileNetV2 without the top layers\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freeze the base model's layers\nbase_model.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add custom layers\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_classes, activation='softmax')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,               # Normalize pixel values\n    rotation_range=20,            # Randomly rotate images\n    width_shift_range=0.2,        # Random horizontal shifts\n    height_shift_range=0.2,       # Random vertical shifts\n    shear_range=0.2,              # Shear transformations\n    zoom_range=0.2,               # Random zooms\n    horizontal_flip=True,         # Flip images horizontally\n    fill_mode='nearest'           # Fill in pixels after transformations\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define directories for train and validation\ntrain_data_dir = '/kaggle/input/roboflow/train'\nval_data_dir = '//kaggle/input/roboflow/valid'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load images from directories\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'  # 2 classes: real and spoof\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_generator = val_datagen.flow_from_directory(\n    val_data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_data=val_generator,\n    validation_steps=val_generator.samples // val_generator.batch_size,\n    epochs=30,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load images from the validation directory\nval_data_dir = '/kaggle/input/roboflow/valid'\n\nval_generator = val_datagen.flow_from_directory(\n    val_data_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False  # Important to avoid shuffling to match true labels\n)\n\n# Validate the model\nval_loss, val_accuracy = model.evaluate(val_generator)\nprint(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\nprint(f'Validation Loss: {val_loss:.4f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define the path to your test data\ntest_data_dir = '/kaggle/input/roboflow/test'\n\n# Create an ImageDataGenerator instance for test data\ntest_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values\n\n# Load the test data using the generator\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(224, 224),  # Resize images to match model input size\n    batch_size=32,\n    class_mode='categorical',  # Specify the class mode\n    shuffle=False  # Important to avoid shuffling to match true labels\n)\n\n# Evaluate the model on the test data\ntest_loss, test_accuracy = model.evaluate(test_generator)\n\n# Print the test results\nprint(f'Test Accuracy: {test_accuracy * 100:.2f}%')\nprint(f'Test Loss: {test_loss:.4f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test data\ntest_loss, test_accuracy = model.evaluate(test_generator)\n\n# Print the test accuracy\nprint(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n# Generate predictions from the model\ntest_generator.reset()  # Reset the generator to make sure we are getting predictions for the entire dataset\npredictions = model.predict(test_generator)\npredicted_classes = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n\n# Get true labels from the test generator\ntrue_labels = test_generator.classes\n\n# Compute confusion matrix\ncm = confusion_matrix(true_labels, predicted_classes)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"/kaggle/working/liveness.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Define the directory where the images are uploaded\nuploaded_images_dir = '/kaggle/input/test-sriram/'  # Replace with your actual directory\n\n# List files in the directory to verify path\nfiles = os.listdir(uploaded_images_dir)\nprint(\"Files in directory:\", files)\n\n# Use a specific file from the directory\ntest_image_filename = 'WhatsApp Image 2024-09-01 at 22.48.04_3a9fea3b.jpg'  # Replace with your actual image file name\ntest_image_path = os.path.join(uploaded_images_dir, test_image_filename)\n\nprint(\"Full image path:\", test_image_path)\n\n# Ensure the path exists\nif not os.path.exists(test_image_path):\n    print(f\"Error: The file {test_image_path} does not exist.\")\nelse:\n    # Proceed with loading and testing the image\n    from tensorflow.keras.preprocessing import image\n    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    def load_and_preprocess_image(img_path):\n        img = image.load_img(img_path, target_size=(224, 224))  # Resize to match model input size\n        img_array = image.img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array = preprocess_input(img_array)\n        return img_array\n\n    # Load and preprocess the image\n    test_image_array = load_and_preprocess_image(test_image_path)\n\n    # Make predictions\n    predictions = model.predict(test_image_array)\n    predicted_class = np.argmax(predictions[0])\n\n    # Display the image and prediction\n    img = image.load_img(test_image_path)\n    plt.imshow(img)\n    plt.title(f'Predicted Class: {predicted_class}')\n    plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}